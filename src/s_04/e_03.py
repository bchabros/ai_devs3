from loguru import loggerfrom bs4 import BeautifulSoupimport openaiimport requestsfrom typing import Dict, List, Optionalimport jsonclass SoftoCrawler:    def __init__(self, api_key: str):        self.base_url = "https://softo.ag3nts.org"        self.visited_urls = set()        self.openai_client = openai.Client(api_key=api_key)    @staticmethod    def get_questions(key: str) -> Dict:        logger.info(f"Pobieranie pytań z centrali")        url = f"https://centrala.ag3nts.org/data/{key}/softo.json"        response = requests.get(url)        questions = response.json()        logger.debug(f"Pobrane pytania: {json.dumps(questions, indent=2, ensure_ascii=False)}")        return questions    @staticmethod    def fetch_page(url: str) -> str:        logger.debug(f"Pobieranie zawartości strony: {url}")        response = requests.get(url)        logger.debug(f"Status odpowiedzi: {response.status_code}")        return response.text    def extract_links(self, html: str) -> List[str]:        logger.debug("Rozpoczęcie ekstrakcji linków")        soup = BeautifulSoup(html, 'html.parser')        links = []        for a in soup.find_all('a', href=True):            href = a['href']            if href.startswith('/'):                href = self.base_url + href            if href.startswith(self.base_url):                links.append(href)        logger.debug(f"Znaleziono {len(links)} linków: {links}")        return links    def analyze_page_for_answer(self, content: str, question: str) -> Optional[str]:        logger.info(f"Analiza strony w poszukiwaniu odpowiedzi na pytanie: {question[:50]}...")        prompt = f"""        Pytanie: {question}        Treść strony:        {content}        Zadania:        1. Przeanalizuj, czy na tej stronie znajduje się odpowiedź na podane pytanie.         2. Jeśli tak, wyekstrahuj zwięzłą odpowiedź.        3. Jeśli nie, odpowiedz "BRAK_ODPOWIEDZI".        Odpowiedz tylko odpowiedzią lub BRAK_ODPOWIEDZI, bez dodatkowych wyjaśnień.        Jeżeli to będzie link (adres url podaj tylko link, jeżeli mail podaj tylko mail bez dodatkowych słów).        """        response = self.openai_client.chat.completions.create(            model="gpt-4o",            messages=[{"role": "user", "content": prompt}],            temperature=0        )        answer = response.choices[0].message.content.strip()        logger.info(f"Otrzymana odpowiedź: {answer[:100]}...")        return None if answer == "BRAK_ODPOWIEDZI" else answer    def should_follow_link(self, link: str, question: str) -> bool:        logger.debug(f"Ocena linku: {link}")        prompt = f"""        Pytanie: {question}        Link: {link}        Czy na podstawie tekstu linku i jego struktury URL możemy przypuszczać,         że może on prowadzić do odpowiedzi na to pytanie?        Odpowiedz tylko TAK lub NIE.        """        response = self.openai_client.chat.completions.create(            model="gpt-4o",            messages=[{"role": "user", "content": prompt}],            temperature=0        )        decision = response.choices[0].message.content.strip() == "TAK"        logger.debug(f"Decyzja dla linku {link}: {'podążamy' if decision else 'pomijamy'}")        return decision    def find_answer(self, question: str, max_depth: int = 6) -> Optional[str]:        logger.info(f"Rozpoczęcie poszukiwania odpowiedzi na pytanie (max głębokość: {max_depth})")        def search_recursive(url: str, depth: int) -> Optional[str]:            logger.debug(f"Przeszukiwanie na głębokości {depth}, URL: {url}")            if depth > max_depth:                logger.warning(f"Osiągnięto maksymalną głębokość ({max_depth}) dla URL: {url}")                return None            if url in self.visited_urls:                logger.debug(f"URL już odwiedzony: {url}")                return None            self.visited_urls.add(url)            content = self.fetch_page(url)            answer = self.analyze_page_for_answer(content, question)            if answer:                logger.success(f"Znaleziono odpowiedź na stronie {url}")                return answer            links = self.extract_links(content)            logger.info(f"Przeszukiwanie {len(links)} linków na głębokości {depth}")            for link in links:                if self.should_follow_link(link, question):                    result = search_recursive(link, depth + 1)                    if result:                        return result            logger.debug(f"Nie znaleziono odpowiedzi w gałęzi {url}")            return None        result = search_recursive(self.base_url, 0)        if result:            logger.success("Znaleziono odpowiedź!")        else:            logger.warning("Nie znaleziono odpowiedzi po przeszukaniu wszystkich ścieżek")        return result    def solve_task(self, key: str) -> Dict[str, str]:        logger.info(f"Rozpoczęcie rozwiązywania zadania.")        questions = self.get_questions(key)        answers = {}        for q_id, question in questions.items():            logger.info(f"Przetwarzanie pytania {q_id}: {question[:50]}...")            self.visited_urls.clear()            answer = self.find_answer(question)            answers[q_id] = answer if answer else "Nie znaleziono odpowiedzi"            logger.info(f"Odpowiedź na pytanie {q_id}: {answers[q_id][:100]}...")        return answers